2021-09-02 15:19:50  [ dispatcher-event-loop-6:24 ] - [ ERROR ]  Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@7890cfea rejected from java.util.concurrent.ThreadPoolExecutor@57200a67[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 14]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:612)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:589)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ dispatcher-event-loop-6:45 ] - [ ERROR ]  Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@2bb89746 rejected from java.util.concurrent.ThreadPoolExecutor@7b8ad166[Shutting down, pool size = 6, active threads = 6, queued tasks = 0, completed tasks = 16]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:228)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ dispatcher-event-loop-6:47 ] - [ ERROR ]  Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@215c66c7 rejected from java.util.concurrent.ThreadPoolExecutor@57200a67[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 14]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:612)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:589)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ dispatcher-event-loop-6:50 ] - [ ERROR ]  Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@5b6c5cb6 rejected from java.util.concurrent.ThreadPoolExecutor@7b8ad166[Shutting down, pool size = 6, active threads = 6, queued tasks = 0, completed tasks = 16]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:228)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ dispatcher-event-loop-2:103 ] - [ ERROR ]  Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@4b22b0f1 rejected from java.util.concurrent.ThreadPoolExecutor@57200a67[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 14]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:612)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:589)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ dispatcher-event-loop-2:105 ] - [ ERROR ]  Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@3523965b rejected from java.util.concurrent.ThreadPoolExecutor@7b8ad166[Shutting down, pool size = 5, active threads = 5, queued tasks = 0, completed tasks = 17]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:228)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:147 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\05\temp_shuffle_26fd44ca-c277-40f0-9aad-e34304437e44
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\05\temp_shuffle_26fd44ca-c277-40f0-9aad-e34304437e44 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:149 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\05\temp_shuffle_26fd44ca-c277-40f0-9aad-e34304437e44
2021-09-02 15:19:50  [ Executor task launch worker for task 18:153 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\02\temp_shuffle_3b6b8a01-d70c-40fa-8ea1-49ffd9720e6d
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\02\temp_shuffle_3b6b8a01-d70c-40fa-8ea1-49ffd9720e6d (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:153 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\02\temp_shuffle_3b6b8a01-d70c-40fa-8ea1-49ffd9720e6d
2021-09-02 15:19:50  [ Executor task launch worker for task 18:156 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\14\temp_shuffle_d0bfacf3-728b-472d-94c7-88144c5edc71
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\14\temp_shuffle_d0bfacf3-728b-472d-94c7-88144c5edc71 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:156 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\14\temp_shuffle_d0bfacf3-728b-472d-94c7-88144c5edc71
2021-09-02 15:19:50  [ Executor task launch worker for task 18:158 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\10\temp_shuffle_1cdf180e-2605-4058-b4be-4a1b082c0d25
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\10\temp_shuffle_1cdf180e-2605-4058-b4be-4a1b082c0d25 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:159 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\10\temp_shuffle_1cdf180e-2605-4058-b4be-4a1b082c0d25
2021-09-02 15:19:50  [ Executor task launch worker for task 18:164 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_b98b22e3-cfe1-4478-a7fd-030058e6a24b
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_b98b22e3-cfe1-4478-a7fd-030058e6a24b (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:164 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_b98b22e3-cfe1-4478-a7fd-030058e6a24b
2021-09-02 15:19:50  [ Executor task launch worker for task 18:165 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_93fdc7a3-3300-4759-bf1e-d3dc4a5ae435
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_93fdc7a3-3300-4759-bf1e-d3dc4a5ae435 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:166 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_93fdc7a3-3300-4759-bf1e-d3dc4a5ae435
2021-09-02 15:19:50  [ Executor task launch worker for task 18:167 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1a\temp_shuffle_8e25408c-d2fd-4347-8c9d-ab10ac7068bc
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1a\temp_shuffle_8e25408c-d2fd-4347-8c9d-ab10ac7068bc (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:168 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1a\temp_shuffle_8e25408c-d2fd-4347-8c9d-ab10ac7068bc
2021-09-02 15:19:50  [ Executor task launch worker for task 18:171 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_dff1daca-d6e4-4703-bcb2-d07f1e35b910
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_dff1daca-d6e4-4703-bcb2-d07f1e35b910 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:172 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_dff1daca-d6e4-4703-bcb2-d07f1e35b910
2021-09-02 15:19:50  [ Executor task launch worker for task 20:177 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_832cafa8-efef-4fa0-9d5a-eb1c3c26214e
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_832cafa8-efef-4fa0-9d5a-eb1c3c26214e (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:179 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_832cafa8-efef-4fa0-9d5a-eb1c3c26214e
2021-09-02 15:19:50  [ Executor task launch worker for task 20:179 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_059a2994-8944-4c0f-94ca-cd7ec0f21de5
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_059a2994-8944-4c0f-94ca-cd7ec0f21de5 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:180 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_059a2994-8944-4c0f-94ca-cd7ec0f21de5
2021-09-02 15:19:50  [ Executor task launch worker for task 20:182 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0a\temp_shuffle_99a4b8b3-70b2-446f-b0e4-f19df1e142b8
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0a\temp_shuffle_99a4b8b3-70b2-446f-b0e4-f19df1e142b8 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:183 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0a\temp_shuffle_99a4b8b3-70b2-446f-b0e4-f19df1e142b8
2021-09-02 15:19:50  [ Executor task launch worker for task 20:183 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\11\temp_shuffle_70780232-3390-4b34-880f-d33bed5a80dd
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\11\temp_shuffle_70780232-3390-4b34-880f-d33bed5a80dd (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:184 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\11\temp_shuffle_70780232-3390-4b34-880f-d33bed5a80dd
2021-09-02 15:19:50  [ Executor task launch worker for task 20:185 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\12\temp_shuffle_66164958-3262-4a12-9d65-6100dfea0b84
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\12\temp_shuffle_66164958-3262-4a12-9d65-6100dfea0b84 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:186 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\12\temp_shuffle_66164958-3262-4a12-9d65-6100dfea0b84
2021-09-02 15:19:50  [ Executor task launch worker for task 20:191 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_348c7849-a22a-4421-8934-f956fee7db80
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_348c7849-a22a-4421-8934-f956fee7db80 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:192 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_348c7849-a22a-4421-8934-f956fee7db80
2021-09-02 15:19:50  [ Executor task launch worker for task 20:193 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\13\temp_shuffle_00208dc5-d6a1-4d46-93d7-e1ecebbe15c8
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\13\temp_shuffle_00208dc5-d6a1-4d46-93d7-e1ecebbe15c8 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:194 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\13\temp_shuffle_00208dc5-d6a1-4d46-93d7-e1ecebbe15c8
2021-09-02 15:19:50  [ Executor task launch worker for task 20:194 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_84639e33-ac3f-47c6-b190-a8e66b69da38
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_84639e33-ac3f-47c6-b190-a8e66b69da38 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:195 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_84639e33-ac3f-47c6-b190-a8e66b69da38
2021-09-02 15:19:50  [ Executor task launch worker for task 20:195 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\18\temp_shuffle_faced802-7ab3-4edc-8f31-cade402b2695
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\18\temp_shuffle_faced802-7ab3-4edc-8f31-cade402b2695 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:196 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\18\temp_shuffle_faced802-7ab3-4edc-8f31-cade402b2695
2021-09-02 15:19:50  [ Executor task launch worker for task 20:198 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1f\temp_shuffle_2ce3b105-ad9a-4d4e-83f7-3f7d07753d85
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1f\temp_shuffle_2ce3b105-ad9a-4d4e-83f7-3f7d07753d85 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:201 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1f\temp_shuffle_2ce3b105-ad9a-4d4e-83f7-3f7d07753d85
2021-09-02 15:19:50  [ Executor task launch worker for task 21:208 ] - [ ERROR ]  Exception in task 1.0 in stage 1.0 (TID 21): C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\18\shuffle_1_21_0.index.6f72db75-b92e-460c-80b9-ed572184320d (系统找不到指定的路径。)
2021-09-02 15:19:50  [ Executor task launch worker for task 18:208 ] - [ ERROR ]  Exception in task 18.0 in stage 0.0 (TID 18): C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\02\temp_shuffle_3b6b8a01-d70c-40fa-8ea1-49ffd9720e6d (系统找不到指定的路径。)
2021-09-02 15:19:50  [ Executor task launch worker for task 20:251 ] - [ ERROR ]  Exception in task 0.0 in stage 1.0 (TID 20): C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\16\temp_shuffle_059a2994-8944-4c0f-94ca-cd7ec0f21de5 (系统找不到指定的路径。)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:303 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1638c0e1-edcd-4d53-b6ca-f7d1aaf553c1
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1638c0e1-edcd-4d53-b6ca-f7d1aaf553c1 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:303 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1638c0e1-edcd-4d53-b6ca-f7d1aaf553c1
2021-09-02 15:19:50  [ Executor task launch worker for task 19:304 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_4ae12c47-ecfe-4171-8ed5-aa472d23f5b7
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_4ae12c47-ecfe-4171-8ed5-aa472d23f5b7 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:305 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0c\temp_shuffle_4ae12c47-ecfe-4171-8ed5-aa472d23f5b7
2021-09-02 15:19:50  [ Executor task launch worker for task 19:305 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\28\temp_shuffle_5b879ce6-d6ea-4cfd-b7aa-064d2f2c7013
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\28\temp_shuffle_5b879ce6-d6ea-4cfd-b7aa-064d2f2c7013 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:305 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\28\temp_shuffle_5b879ce6-d6ea-4cfd-b7aa-064d2f2c7013
2021-09-02 15:19:50  [ Executor task launch worker for task 19:306 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\34\temp_shuffle_b19c6748-437e-4cc0-909f-2aae9cba4f26
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\34\temp_shuffle_b19c6748-437e-4cc0-909f-2aae9cba4f26 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:306 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\34\temp_shuffle_b19c6748-437e-4cc0-909f-2aae9cba4f26
2021-09-02 15:19:50  [ Executor task launch worker for task 19:306 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_da623bc1-9f21-4f2e-89b5-db71c8382319
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_da623bc1-9f21-4f2e-89b5-db71c8382319 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:307 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_da623bc1-9f21-4f2e-89b5-db71c8382319
2021-09-02 15:19:50  [ Executor task launch worker for task 19:307 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\24\temp_shuffle_96f76bc4-b2b6-493c-ab2a-4901355ad678
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\24\temp_shuffle_96f76bc4-b2b6-493c-ab2a-4901355ad678 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:307 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\24\temp_shuffle_96f76bc4-b2b6-493c-ab2a-4901355ad678
2021-09-02 15:19:50  [ Executor task launch worker for task 19:307 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1bb844dc-6b81-4aa1-a0d8-d0057a9a5cd0
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1bb844dc-6b81-4aa1-a0d8-d0057a9a5cd0 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:308 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\17\temp_shuffle_1bb844dc-6b81-4aa1-a0d8-d0057a9a5cd0
2021-09-02 15:19:50  [ Executor task launch worker for task 19:308 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\01\temp_shuffle_7b659b9d-7e2a-4c51-bd98-ed2bba1bb5a4
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\01\temp_shuffle_7b659b9d-7e2a-4c51-bd98-ed2bba1bb5a4 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:308 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\01\temp_shuffle_7b659b9d-7e2a-4c51-bd98-ed2bba1bb5a4
2021-09-02 15:19:50  [ Executor task launch worker for task 19:309 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\31\temp_shuffle_d1333d51-c9f8-4773-9739-b5e55c2f5aff
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\31\temp_shuffle_d1333d51-c9f8-4773-9739-b5e55c2f5aff (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:309 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\31\temp_shuffle_d1333d51-c9f8-4773-9739-b5e55c2f5aff
2021-09-02 15:19:50  [ Executor task launch worker for task 19:309 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_a28857ac-7c7b-4053-bc2a-1872773ecb70
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_a28857ac-7c7b-4053-bc2a-1872773ecb70 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:309 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\1b\temp_shuffle_a28857ac-7c7b-4053-bc2a-1872773ecb70
2021-09-02 15:19:50  [ Executor task launch worker for task 19:309 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0f\temp_shuffle_cf3edc04-10f9-43cc-9120-af87bce47563
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0f\temp_shuffle_cf3edc04-10f9-43cc-9120-af87bce47563 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:310 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0f\temp_shuffle_cf3edc04-10f9-43cc-9120-af87bce47563
2021-09-02 15:19:50  [ Executor task launch worker for task 19:310 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\22\temp_shuffle_85d13aa5-0757-4a19-b8ee-5336e2a8f260
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\22\temp_shuffle_85d13aa5-0757-4a19-b8ee-5336e2a8f260 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:310 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\22\temp_shuffle_85d13aa5-0757-4a19-b8ee-5336e2a8f260
2021-09-02 15:19:50  [ Executor task launch worker for task 19:310 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_d87e3c8d-4dbe-4dfa-9c87-58557b95d467
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_d87e3c8d-4dbe-4dfa-9c87-58557b95d467 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:310 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\19\temp_shuffle_d87e3c8d-4dbe-4dfa-9c87-58557b95d467
2021-09-02 15:19:50  [ Executor task launch worker for task 19:311 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\27\temp_shuffle_564ed019-17a7-48f9-a52d-2675fbb07ca6
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\27\temp_shuffle_564ed019-17a7-48f9-a52d-2675fbb07ca6 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:311 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\27\temp_shuffle_564ed019-17a7-48f9-a52d-2675fbb07ca6
2021-09-02 15:19:50  [ Executor task launch worker for task 19:316 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\32\temp_shuffle_148d22a5-d4f5-4320-a1f6-4162e31a6c84
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\32\temp_shuffle_148d22a5-d4f5-4320-a1f6-4162e31a6c84 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:316 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\32\temp_shuffle_148d22a5-d4f5-4320-a1f6-4162e31a6c84
2021-09-02 15:19:50  [ Executor task launch worker for task 19:317 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0e\temp_shuffle_0d8064b1-a5e7-4d09-ad26-9493ef89d0d9
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0e\temp_shuffle_0d8064b1-a5e7-4d09-ad26-9493ef89d0d9 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:318 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0e\temp_shuffle_0d8064b1-a5e7-4d09-ad26-9493ef89d0d9
2021-09-02 15:19:50  [ Executor task launch worker for task 19:318 ] - [ ERROR ]  Uncaught exception while reverting partial writes to file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0d\temp_shuffle_fc5d11e8-af28-419a-b419-05c626a4d305
java.io.FileNotFoundException: C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0d\temp_shuffle_fc5d11e8-af28-419a-b419-05c626a4d305 (系统找不到指定的路径。)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.$anonfun$revertPartialWritesAndClose$2(DiskBlockObjectWriter.scala:219)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1386)
	at org.apache.spark.storage.DiskBlockObjectWriter.revertPartialWritesAndClose(DiskBlockObjectWriter.scala:216)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(BypassMergeSortShuffleWriter.java:278)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-09-02 15:19:50  [ Executor task launch worker for task 19:319 ] - [ ERROR ]  Error while deleting file C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0d\temp_shuffle_fc5d11e8-af28-419a-b419-05c626a4d305
2021-09-02 15:19:50  [ Executor task launch worker for task 19:319 ] - [ ERROR ]  Exception in task 19.0 in stage 0.0 (TID 19): C:\Users\xiaopao\AppData\Local\Temp\blockmgr-04dc34fd-11fe-4ea2-aebe-59c746166a42\0f\temp_shuffle_cf3edc04-10f9-43cc-9120-af87bce47563 (系统找不到指定的路径。)
